{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M00Ue9aOVFvF"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from pickle import dump\n",
        "from keras.applications.vgg16 import VGG16\n",
        "#from keras.preprocessing.image import load_img\n",
        "#from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "\n",
        "# extract features from each photo in the directory\n",
        "def extract_features(directory):\n",
        "\t# load the model\n",
        "\tmodel = VGG16()\n",
        "\t# re-structure the model\n",
        "\tmodel.layers.pop()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\t# summarize\n",
        "\tprint(model.summary())\n",
        "\t# extract features from each photo\n",
        "\tfeatures = dict()\n",
        "\tfor name in listdir(directory):\n",
        "\t\t# load an image from file\n",
        "\t\tfilename = directory + '/' + name\n",
        "\t\timage = load_img(filename, target_size=(224, 224))\n",
        "\t\t# convert the image pixels to a numpy array\n",
        "\t\timage = img_to_array(image)\n",
        "\t\t# reshape data for the model\n",
        "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t\t# prepare the image for the VGG model\n",
        "\t\timage = preprocess_input(image)\n",
        "\t\t# get features\n",
        "\t\tfeature = model.predict(image, verbose=0)\n",
        "\t\t# get image id\n",
        "\t\timage_id = name.split('.')[0]\n",
        "    # store feature\n",
        "\t\tfeatures[image_id] = feature\n",
        "\t\tprint('>%s' % name)\n",
        "\treturn features\n",
        "\n",
        "# extract features from all images\n",
        "#directory = 'dataset'\n",
        "#features = extract_features(directory)\n",
        "#print('Extracted Features: %d' % len(features))\n",
        "# save to file\n",
        "#dump(features, open('features.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "import tensorflow\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "#from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n"
      ],
      "metadata": {
        "id": "-6SAJI-hVf3N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjFz05g_Wgsm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
